[{"title":"profiler tensorboard","url":"/2025/05/27/profiler-tensorboard/","content":"\n# tensorboard\n\n参考链接：\n\nTensorFlow TensorBoard:\n\n[https://www.tensorflow.org/tensorboard?hl=zh-cn](https://www.tensorflow.org/tensorboard?hl=zh-cn)\n\n知乎：\n\n[https://zhuanlan.zhihu.com/p/471198169](https://zhuanlan.zhihu.com/p/471198169)\n\n## 在PyTorch中使用TensorBoard\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nSummaryWriter类将PyTorch模型和指标记录到文件夹中\n\n[https://pytorch.org/tutorials/recipes/recipes/tensorboard\\_with\\_pytorch.html](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html)\n\n## 安装TensorBoard\n\n将runs文件夹的log数据可视化需要安装tensorboard\n\n```bash\npip install tensorboard\ntensorboard --logdir=runs\n```\n\n## torch.utils.tensorboard\n\n[https://pytorch.org/docs/stable/tensorboard.html](https://pytorch.org/docs/stable/tensorboard.html)\n\n*   scalar\n    \n*   scalars\n    \n*   histogram\n    \n*   image\n    \n*   images\n    \n*   figure\n    \n*   video\n    \n*   audio\n    \n*   text\n    \n*   graph\n    \n*   embedding\n    \n*   pr\\_curve\n    \n*   custom\\_scalars\n    \n*   mesh\n    \n*   hparams\n    \n\n## 用TensorBoard可视化模型、数据和训练的demo\n\n[https://pytorch.org/tutorials/intermediate/tensorboard\\_tutorial.html](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\n\n## torch.profiler\n\n作用：在训练和推理期间收集性能指标。profiler的上下文管理器API可用于更好地了解哪些模型运算符的成本更高，检查它们的输入形状和堆栈跟踪，研究设备内核活动并可视化执行跟踪。\n\n将tensorboard插件与PyTorch Profiler结合使用，以检测模型的性能瓶颈：\n\n[https://pytorch.ac.cn/tutorials/intermediate/tensorboard\\_profiler\\_tutorial.html](https://pytorch.ac.cn/tutorials/intermediate/tensorboard_profiler_tutorial.html)\n\n1.  准备数据和模型\n    \n2.  使用性能分析器记录执行事件\n    \n3.  运行性能分析器\n    \n4.  使用TensorBoard查看结果并分析模型性能\n    \n5.  在性能分析器的帮助下提高性能\n    \n6.  使用其他高级功能分析性能\n    \n7.  实践：在musa设备上分析PyTorch性能\n    \n\n[PyTorch Profiler — PyTorch Tutorials 2.5.0+cu124 documentation](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)\n\n用于分析PyTorch程序的性能，帮助开者深入了解模型的运行情况，以便进行优化。它能够捕捉和记录PyTorch程序在训练和推理时的各项性能指标，包括时间消耗、内存使用、各个操作的执行情况等，帮助找出瓶颈并进行优化。\n\n## 指标\n\n### GPU 利用率\n\nGPU繁忙时间与所有步骤时间的比值，越高越好。所有步骤时间是所有分析器步骤的总时间。GPU繁忙时间是“所有步骤时间”期间至少有一个GPU内核在此GPU上运行的时间。但是，这种高级利用率指标是粗略的。它无法告诉有多少SM正在使用中。例如，一个单线程连续运行的内核将获得100%的GPU利用率。\n\n### 估计SM效率\n\n估计的流多处理器效率。越高越好。内核的这个指标，SM\\_Eff\\_K=min(此内核的块/此GPU的SM数量，100%)。这个总体数字是所有内核的SM\\_Eff\\_K的总和，按内核的执行持续时间加权，除以“所有步骤时间”。它显示了GPU流多处理器的利用率。虽然它比GPU利用率更细粒度，但它仍然不能说明全部情况。例如，每个块只有一个线程的内核无法充分利用每个SM。\n\n### 估计实现占用率\n\n对于大多数情况，例如内存带宽受限的内核，更高的值通常意味着更好的性能，特别是当初始值非常低时。占用率的定义（占用率是SM上的活动warp与SM支持的最大活动warp数之比）。内核的理论占用率是此内核的上限占用率，受内核形状，内核使用的资源和GPU计算能力等多种因素限制。内核的估计实现占用率OCC\\_K=min(内核的线程数/SM数/每个SM的最大线程数，内核的理论占用率），这个总体数字是使用内核的执行持续时间作为权重的所有OCC\\_K的加权总和。它显示了细粒度的低级GPU利用率。\n\n### 使用Tensor Cores的内核时间\n\nTensor Core内核的总GPU时间/所有内核的总GPU时间。值越高越好。Tensor Cores是可用于Volta GPU以及跟高版本的混合精度浮点运算。cuDNN和cuBLAS库包含多个启用Tensor Cores的GPU内核，可用于大多数卷积和GEMM操作。此数字显示GPU上所有内核中的Tensor Cores使用时间比率。\n\n### num of workers\n\n指在数据加载过程中用于并行加载数据的工作线程数量。它与PyTorch的DataLoader相关，DataLoader是负责将数据集分成小批量，并将这些批量加载到模型中的。num\\_workers参数指定了加载数据时使用多少个子进程来并行处理数据。有助于加速数据加载的速度，尤其是在数据集较大且需要进行大量预处理时。\n\n在TensorBoard中查看时，num of workers反映的是训练过程中数据加载部分使用的并行度（即多少个动作线程被用来加载数据）。这个指标有助于了解数据加载的效率和瓶颈，尤其是在数据加载时间较长，是否可以通过增加num\\_workers来加速。\n\n## 启动tensorboard\n\n1.  tensorboard --logdir=./log，网页打开http://localhost:6006/\n    \n2.  TensorBoard 只会在 `localhost`（即本机）上监听，其他机器无法访问。如果你希望从其他设备访问，需确保它绑定到所有网络接口。\n    \n\n通过添加 `--bind_all` 参数来使其监听所有接口：\n\n```bash\ntensorboard --logdir=./log --bind_all\n```\n\n打开网址：http://<机器的IP地址>:6006/\n\n## 查看tensorboard的进程\n\n```bash\nps aux | grep tensorboard\nkill -9 PID\n```\n\n## FAQ\n\n1.  TensorBoard正常启动，浏览器加载卡住\n    \n\n```bash\ntensorboard --logdir=runs --port 6688\n```\n\n![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/mxPOGQW4LX19nKa9/img/eca37d4e-c26c-4b65-8f2f-2d2ff94d1520.png)\n\n检查vscode的转发端口，清理不使用的端口转发项，为tensorboard设置一个新的端口。\n\n参考链接：[https://blog.csdn.net/baidu\\_32500247/article/details/140145323](https://blog.csdn.net/baidu_32500247/article/details/140145323)\n\n2.  vscode中集成tensorboard\n    \n\n参考链接：[https://devblogs.microsoft.com/python/python-in-visual-studio-code-february-2021-release/#tensorboard-integration](https://devblogs.microsoft.com/python/python-in-visual-studio-code-february-2021-release/#tensorboard-integration)\n\n3.  trace视图无法正常工作，不显示任何内容\n    \n\n*   将远程服务器中的log文件scp到本地windows系统\n    \n*   在Chrome浏览器中输入chrome://tracing\n    \n*   点击load，加载JSON文件\n    \n\n1.  DataLoader的Time Duration为0\n    \n\n推测是计算到了CPU Exec中，没有被显示地单独统计，因为数据加载的操作大部分是由CPU完成的。此外，数据加载过程非常短，低于最小的时间阈值，也会导致这个结果。\n\n![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/mxPOGQW4LX19nKa9/img/5f41499e-b565-4ced-b58a-a7c0c7650285.png)\n\n![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/mxPOGQW4LX19nKa9/img/93ad9bf8-b13b-45d4-bf07-883bf3da7ef3.png)\n"},{"title":"pdb debug","url":"/2025/05/27/pdb-debug/","content":"\n\n# pdb debug工具\n\n## 介绍\n\npdb是Python内置的交互式源代码调试器，提供了设置断点、单步执行、查看堆栈帧、检查变量等功能，帮助开发者有效地调试代码。\n\n## 基本用法\n\n1.  在代码中设置断点\n    \n\n在需要调试的代码位置插入以下代码行\n\n```bash\nimport pdb\npdb.set_trace()\n```\n\n2.  使用内置的breakpoint()函数（适用于Python3.7及以上版本）\n    \n\n从Python3.7开始，可以使用内置的breakpoint()函数代替上述方法，当程序执行到breakpoint()时，会暂停并进入调试模式。\n\n```bash\ndef double(x):\n    breakpoint()\n    return x * 2\n\nval = 3\nprint(f\"{val} * 2 is {double(val)}\")\n```\n\n3.  从命令行直接运行脚本并进入调试模式\n    \n\n可以在运行Python脚本时通过命令行参数直接启动调试器，这将以调试模式启动脚本，程序会在第一行代码处暂停。\n\n```bash\npython -m pdb your_script.py\n```\n\n## 常用调试命令\n\n*   l (list)：显示当前代码行及其上下文。\n    \n*   n (next)：执行下一行代码。\n    \n*   s (step)：进入函数内部。\n    \n*   c (continue)：继续执行程序直到遇到下一个断点。\n    \n*   p (print)：打印变量的值，例如 p variable\\_name。\n    \n*   q (quit)：退出调试器。\n"},{"title":"torch compile","url":"/2025/05/27/torch-compile/","content":"\n\n## `torch.compile` 的编译流程\nPyTorch + Inductor + Triton的整个编译流程，特别是`triton kernel`生成与编译分析这部分的过程。\n\n### 整体编译流程\n1. 前端捕获（TorchDynamo）\n    \n    捕获PyTorch的eager模型，生成一个FX Graph（中间表示IR）\n2. 图优化与分区（AOTAutograd + Decompositions）\n\n    对FX Graph进行算子分解（decomposition）、分区（partition）等预处理。\n3. 后端Lowering（Inductor）\n\n    Inductor接受FX Graph，将算子Lowering成调度后语义（Schedulers）。\n    \n    部分算子会映射到Triton-compatible kernels, 由Inductor创建出表示Triton的kernel源码（字符串）\n4. Triton编译器调用\n    \n    对于这些Triton kernel源码（通常是Python函数字符串），Triton编译器执行：\n\n        AST（抽象语法树）分析：将kernel函数代码解析为AST。\n        语义检查与IR构造：建立Triton的中间表示（SSA IR）。\n        后端代码生成：转成GPU可执行代码，比如PTX（NVIDIA）。\n\n\n## `torch.compile` 常用 Backend 整理（PyTorch 2.x+）\n\n### 🧠 Backend 一览表\n\n| Backend 名称                         | 描述/特点                                         | 是否默认 | 适用场景/建议                            |\n| ---------------------------------- | --------------------------------------------- | ---- | ---------------------------------- |\n| `\"inductor\"`                       | ⚙️ 默认 backend，基于 Triton 和 C++，性能好、支持广泛        | ✅ 默认 | 推荐首选，支持大部分算子，适用于通用加速优化             |\n| `\"eager\"`                          | PyTorch 原生模式，不做编译优化                           | ❌    | ✅ Debug 模式；模型不支持编译、想跳过加速或便于排查      |\n| `\"aot_eager\"`                      | AOT Autograd + Eager，开启 trace 但不做 Inductor 优化 | ❌    | Debug 早期图 trace 问题；不编译后端，只记录图结构    |\n| `\"nvfuser\"`                        | 早期 Fusion backend，面向 CUDA（正在逐步弃用）             | ❌    | CUDA 模型上实验使用，不推荐新项目使用              |\n| `\"aot_ts_nvfuser\"`                 | TorchScript + NVFuser（图优化 + Fusion）           | ❌    | 适用于 TorchScript 路径；性能不一定稳定         |\n| `\"aot_torchxla_traced\"`            | 用于 XLA（TPU）后端，例如在 Google Cloud TPU 上          | ❌    | TPU 训练任务必须使用                       |\n| `\"aot_torchxla\"`                   | 同上，非 traced 版本                                | ❌    | 更可控但 trace 不完整，实验可用                |\n| `\"ipex\"`                           | Intel Extension for PyTorch，适用于 Intel CPU/GPU | ❌    | 在 Intel 平台上推荐使用（x86 CPU 加速明显）      |\n| `\"openxla\"` / `\"inductor_openxla\"` | 为 OpenXLA 项目构建的 backend，主要用于部署                | ❌    | 高性能部署场景，开发者可试试 OpenXLA 编译路径（还不太成熟） |\n\n### ✅ 常用配置示例\n\n```python\nimport torch\n\n# 默认使用 inductor\nopt_model = torch.compile(model)\n\n# 使用指定 backend\nopt_model = torch.compile(model, backend=\"aot_eager\")  # 或 \"eager\" / \"ipex\" 等\n\n# Debug 编译失败时用 fallback\ntorch._dynamo.config.suppress_errors = True\n```\n\n### 🔍 调试建议\n\n| 需求                   | 推荐做法                                                |\n| -------------------- | --------------------------------------------------- |\n| 想知道是哪个算子不支持          | 设置 `TORCH_LOGS=\"+dynamo\"`，或 `TORCHDYNAMO_VERBOSE=1` |\n| 想 dump 编译图           | `torch._dynamo.export(model, inputs)`               |\n| 想强制 fallback 到 eager | 使用 backend=\"eager\"，或开启 suppress\\_errors             |\n| 编译 crash，但想继续跑       | `torch._dynamo.config.suppress_errors = True`       |\n| 想 benchmark 对比       | 运行多次 warmup 后手动计时                                   |\n\n---\n\n### 🚨 fallback 到 `eager` 有何区别？\n\n当 `torch.compile()` 编译失败时（如 GPU 类型不支持），会 fallback 到 `eager`，这时：\n\n- 模型依然是用 `model_opt = torch.compile(model)` 生成的；\n- 实际执行会自动使用原始 Python 模型，不再启用编译加速；\n- 与直接运行 `model(x)` 无本质区别，仅多一层包装；\n- 可以通过 `torch._dynamo.config.suppress_errors = True` 开启 fallback。\n\n---\n\n### 🧪 如何查看当前后端是否启用成功？\n\n```python\nimport torch._dynamo\nprint(torch._dynamo.explain(model, args))  # 分析编译情况\n```\n\n或设置环境变量调试：\n```bash\nexport TORCH_LOGS=\"+dynamo\"     # 显示编译日志\nexport TORCHDYNAMO_VERBOSE=1    # 显示更多 debug 信息\n```\n\n---\n\n### 🧩 注册自定义 backend 示例（以 MUSA 为例）：\n\n```python\ndef musa_backend(gm, example_inputs):\n    # 替代 torch._inductor.compile_fx 的逻辑\n    ...\n    return compiled_fn\n\ntorch._dynamo.optimizations.backends.register_backend(\"musa_inductor\", musa_backend)\n\nopt_model = torch.compile(model, backend=\"musa_inductor\")\n```\n\n---\n\n"},{"title":"GPU Performance","url":"/2025/05/27/GPU-Performance/","content":"\n# GPU算力与带宽指标以及测试方法\n\n来源项目：智源基础规格评测\n\n## 算力\n\n### 测试项\n\n数据类型包括：BF16、FP16、FP32、FP64、FP8、INT8、TF32等。\n\n|  名称  |  位宽  |  精度范围  |  特点与用途  |\n| --- | --- | --- | --- |\n|  FP64  |  64位  |  极高精度  |  科学计算、金融分析、高精度仿真  |\n|  FP32  |  32位  |  高精度  |  深度学习训练常用默认精度  |\n|  TF32  |  19-bit (in 32-bit slot)  |  FP32范围，精度低于FP32  |  NVIDIA特有：用于加速训练，保持数值稳定性  |\n|  FP16  |  16位  |  中精度  |  深度学习训练和推理中的主流低精度格式  |\n|  BF16  |  16位  |  FP32范围，精度低  |  Google主推：训练更稳定，兼容FP32范围  |\n|  FP8  |  8位  |  精度非常低  |  最新研究方向，推理为主（如 transformer 推理）  |\n|  INT8  |  8位  |  离散整数  |  推理加速，速度快，功耗低，量化模型常用  |\n\n### 算力的定义\n\n指系统处理数据、执行计算任务的能力，通常以单位时间内完成的计算量衡量。\n\nTFLOPS常用于AI推理芯片，统计的是每秒的操作次数。\n\n### 算力的测试方法\n\n调用通用矩阵乘法进行测试，m\\*k,k\\*n的两个矩阵一次iter，ops=m\\*n\\*k\\*2(每次乘加运算共两次)，这个值除以耗时。\n\n## 带宽\n\n包括interconnect-MPI\\_interserver、interconnect-MPI\\_intraserver、interconnect-P2P\\_interserver、interconnect-P2P\\_intraserver、interconnect-h2d、main\\_memory-bandwidth、main\\_memory-capacity\n\n|  项目名称  |  测什么？  |  应用场景  |\n| --- | --- | --- |\n|  interconnect-MPI\\_interserver  |  跨机 MPI 带宽/延迟  |  多节点训练  |\n|  interconnect-MPI\\_intraserver  |  单机 MPI 通信  |  多进程训练、NUMA 架构  |\n|  interconnect-P2P\\_interserver  |  跨机 GPU 直连传输  |  GPU RDMA 通信评估  |\n|  interconnect-P2P\\_intraserver  |  单机 GPU 直连传输  |  多 GPU 通信，NVLink 性能评估  |\n|  interconnect-h2d  |  CPU → GPU 传输带宽  |  DataLoader 吞吐测试  |\n|  main\\_memory-bandwidth  |  内存带宽  |  大批数据加载、预处理性能评估  |\n|  main\\_memory-capacity  |  内存容量  |  检查是否能跑大模型  |\n\ninterconnect-MPI\\_intraserver：调用all reduce算子测试。\n\n[https://tech.preferred.jp/en/blog/technologies-behind-distributed-deep-learning-allreduce/](https://tech.preferred.jp/en/blog/technologies-behind-distributed-deep-learning-allreduce/)\n\n计算方式：它通过将计算和通信均匀地分布在所有参与进程上来消除瓶颈进程。\n\n数据大小SIZE，进程个数gpu\\_nums，2\\*SIZE\\*（gpu\\_nums-1）/gpu\\_Nums/times\n\ninterconnect-P2P\\_intraserver：服务器内不同设备之间点对点互联带宽，衡量GPU到GPU之间的通信速度。不经过host。\n\n计算方式：SIZE/times\n\ninterconnect-h2d：从主机向设备端传输数据的带宽。\n\n计算方式：SIZE/times\n\nmain\\_memory-bandwidth：设备显存带宽\n\n计算方式：从显存读取，再写入到显存。global memory的读+写，所以2\\*SIZE/times\n\nmain\\_memory-capacity：显存容量\n\n计算方法：在不崩溃、不 OOM 的情况下，可以分配的显存总量。循环分配多个 block 的显存，直到 `musaMalloc` 失败，记录已成功分配的总量，即为主存容量估计。\n\n## benchmark\n\nPyTorch算子或原语，调用pytorch算子测试。\n\n调用torch.mm算子来测试算力，计算方法与toolkit相同。\n\n## toolkit\n\n厂商专用工具，二进制可执行文件或者CUDA C/C++源码，直接调用C++代码。\n\n有的调用了mudnn有的调用了mublas的matmal，调用mudnn就是cpp文件，调用mublas就是mu文件。\n\n计算方式是一样的，做矩阵乘法m\\*k,k\\*n的两个矩阵一次iter，ops=m\\*n\\*k\\*2(每次乘加运算共两次)\n\nTFLOPS = FLOPS / 1.0e12;\n\n![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlK5MXNVW2QqDv/img/51bc58ba-3880-4fc8-9d83-56b9b708258f.png)\n"},{"title":"tmux","url":"/2025/03/10/tmux/"},{"title":"docker","url":"/2025/03/08/docker/","content":"\n- [引言](#引言)\n  - [Docker是什么](#docker是什么)\n  - [解决了哪些问题](#解决了哪些问题)\n- [Docker的原理](#docker的原理)\n  - [容器 vs. 虚拟机](#容器-vs-虚拟机)\n  - [Docker的核心组件](#docker的核心组件)\n  - [Docker底层技术](#docker底层技术)\n- [Docker的安装与配置](#docker的安装与配置)\n  - [在Linux系统上的安装](#在linux系统上的安装)\n  - [基本配置](#基本配置)\n- [Docker基本使用](#docker基本使用)\n  - [镜像管理](#镜像管理)\n  - [容器管理](#容器管理)\n  - [数据持久化](#数据持久化)\n  - [网络配置](#网络配置)\n- [Docker进阶用法](#docker进阶用法)\n  - [Dockerfile编写与优化](#dockerfile编写与优化)\n  - [Docker Compose简介](#docker-compose简介)\n  - [常见服务部署](#常见服务部署)\n  - [通过SSH远程登录Docker容器](#通过ssh远程登录docker容器)\n- [相关链接](#相关链接)\n\n\n# 引言\n## Docker是什么\n&emsp;&emsp;Docker是一种基于容器的虚拟化技术，它能够将应用及其所有依赖打包到一个独立的环境中运行。Docker使应用能够在任何支持Docker的环境中运行，而不会受到底层操系统或硬件的影响。\n\n&emsp;&emsp;Docker由Docker引擎提供支持，它使用容器来运行应用程序。与传统的虚拟机不同，Docker容器直接运行在宿主机的内核之上，因此更轻量，更高效。\n\nDocker主要由以下核心组件组成:\n\n  **镜像(Image)**：应用及其环境的只读模板，可以用来创建容器。\n  \n  **容器(Container)**：基于镜像运行的实例，彼此隔离，类似于轻量级虚拟机。\n  \n  **仓库(Registry)**：存储和分发镜像的地方，如Docker Hub、阿里云镜像仓库等。\n## 解决了哪些问题\n1. 环境一致性问题\n2. 依赖管理与部署复杂度\n3. 资源占用高、启动慢\n4. 持续集成与交付（CI/CD）困难\n5. 迁移和扩展困难\n\n# Docker的原理\n## 容器 vs. 虚拟机\n&emsp;&emsp;虚拟机是传统的虚拟化方式。它通过Hypervisor(虚拟机管理程序)在宿主机上运行多个独立的操作系统，每个虚拟机都有自己的内核、文件系统和应用程序。因此，虚拟机的隔离性强，但资源开销大，启动慢。\n\n&emsp;&emsp;Docker容器不需要额外的操作系统，而是共享宿主机的内核，并利用Namespace和Cgroups进行资源隔离和管理。这样容器可以在不影响其他应用的情况下运行，并且占用更少的资源，启动速度极快。\n\n## Docker的核心组件\n1. 镜像\n\n   Docker镜像是一个只读模板，包含了运行应用所需的所有文件、环境变量和依赖库。Docker容器就是基于镜像创建的。\n   \n   通过docker pull从仓库下载镜像，例如：\n   ```sh\n   docker pull ubuntu:latest\n   ```\n   或者通过docker build自定义构建镜像（使用Dockerfile）。\n2. 容器\n   \n   容器时镜像的运行实例，它包含了应用程序及其运行时环境，并且相互隔离。\n\n   通过docker run启动一个容器，例如：\n   ```sh\n   docker run -it ubuntu /bin/bash\n   ```\n   容器可以随时停止、重启、删除，而不会影响宿主机环境。\n3. 仓库\n\n&emsp;&emsp;Docker Registry是存储和分发Docker镜像的地方，常见的公共镜像仓库由Docker Hub、阿里云镜像仓库等。\n\n&emsp;&emsp;docker push：上传镜像到仓库\n\n&emsp;&emsp;docker pull：从仓库拉取镜像\n## Docker底层技术\n1. Namespace（命名空间）————资源隔离\n   \n&emsp;&emsp;Namespace是Linux内核提供的隔离机制，Docker通过Namespace让每个容器由独立的进程、网络、文件系统等。不同容器的进程互不干扰即进程隔离，每个容器有独立的IP和端口即网络隔离，每个容器有自己的根文件系统即文件系统隔离，不同容器的共享内存、信号量等互不干扰即进程间通信隔离。\n\n2. Cgroups（Control Groups）————资源控制\n   \n&emsp;&emsp;Cgroups允许Docker限制容器的CPU、内存、网络、IO资源，防止某个容器占用过多资源，影响主机性能。如限制容器使用1个CPU核心和512MB内存：\n```sh\ndocker run --cpus=1 --memory=512m ubuntu\n```\n\n3. UnionFS（联合文件系统）————镜像分层\n&emsp;&emsp;UnionFS是Docker镜像的存储机制，它允许多个文件系统层叠加，从而提高存储效率。Docker镜像由多个只读层组成，容器运行时会添加一个可写层。只读层是镜像的基础层（如Ubuntu、Python依赖等）。可写层是运行容器时动态创建，存储用户的修改。通过docker commit可以保存容器的可写层，形成新的镜像。\n\n# Docker的安装与配置\n## 在Linux系统上的安装\n1. 更新系统并安装必要的依赖\n```sh\nsudo apt update && sudo apt install -y ca-certificates curl gnupg\n```\n2. 添加Docker官方GPG密钥\n```sh\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo tee /etc/apt/keyrings/docker.asc > /dev/null\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n```\n3. 添加Docker官方软件源\n```sh\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\nsudo apt update\n```\n4. 安装Docker引擎\n```sh\nsudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n```\n5. 启动并设置Docker开机自启\n```sh\nsudo systemctl enable --now docker\n```\n6. 验证Docker是否安装成功\n```sh\ndocker --version\ndocker run hello-world\n```\n7. 将当前用户加入Docker组（可选，避免每次使用sudo）\n```sh\nsudo usermod -aG docker $USER\nnewgrp docker  # 重新加载用户组\n```\n## 基本配置\n1. 配置国内镜像加速\n\n&emsp;&emsp;Docker默认从Docker Hub拉取镜像，但由于网络原因，国内拉取速度较慢。可以配置国内镜像加速器（如阿里云、腾讯云等）：\n\n&emsp;&emsp;编辑Docker配置文件，若不存在，手动创建：\n```sh\nsudo mkdir -p /etc/docker\nsudo nano /etc/docker/daemon.json\n```\n&emsp;&emsp;添加以下内容，以阿里云为例：\n```sh\n{\n  \"registry-mirrors\": [\"https://<你的加速器地址>\"]\n}\n```\n&emsp;&emsp;保存并重启Docker服务：\n```sh\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n2. 修改Docker默认存储路径\n\n&emsp;&emsp;Docker默认将容器和镜像存储在/var/lib/docker，如果磁盘空间有限，可以将存储位置修改到其他目录，如/data/docker。步骤如下：\n\n&emsp;&emsp;停止Docker服务\n```sh\nsudo systemctl stop docker\n```\n&emsp;&emsp;移动默认存储目录\n```sh\nsudo mv /var/lib/docker /data/docker\n```\n&emsp;&emsp;修改Docker配置文件（/etc/docker/daemon.json）并添加以下内容：\n```sh\n{\n  \"data-root\": \"/data/docker\"\n}\n```\n&emsp;&emsp;重启Docker服务\n```sh\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n&emsp;&emsp;验证存储路径\n```sh\ndocker info | grep \"Docker Root Dir\"\n```\n3. 启用远程API（用于SSH远程管理）\n\n&emsp;&emsp;默认情况下，Docker只能在本机运行。如果需要远程管理Docker（如使用SSH连接并控制远程主机上的Docker），可以开启Docker API远程访问。步骤如下：\n\n&emsp;&emsp;修改Docker配置文件\n```sh\n{\n  \"hosts\": [\"tcp://0.0.0.0:2375\", \"unix:///var/run/docker.sock\"]\n}\n```\n&emsp;&emsp;重启Docker服务\n```sh\nsudo systemctl restart docker\n```\n&emsp;&emsp;在远程客户端访问Docker主机\n```sh\nexport DOCKER_HOST=\"tcp://远程服务器IP:2375\"\ndocker ps\n```\n&emsp;&emsp;如果能正确返回容器列表，则说明远程访问已启用。\n\n4. 限制Docker资源使用\n\n&emsp;&emsp;在多容器环境下，为了避免某些容器占用过多资源，可以使用Cgroups限制CPU、内存等。\n\n&emsp;&emsp;限制CPU核心数\n```sh\ndocker run --cpus=1 ubuntu\n```\n&emsp;&emsp;限制内存\n```sh\ndocker run --memory=512m ubuntu\n```\n&emsp;&emsp;限制CPU占用率\n```sh\ndocker run --cpu-shares=512 ubuntu\n```\n# Docker基本使用\n## 镜像管理\n1. 拉取镜像\n```sh\ndocker pull ubuntu:20.04\n```\n2. 列出本地镜像\n```sh\ndocker images\n```\n3. 删除镜像\n```sh\ndocker rmi 镜像ID\n```\n&emsp;&emsp;删除未使用的镜像，节省磁盘空间\n```sh\ndocker image prune -a\n```\n4. 使用已有容器生成新的镜像\n\n&emsp;&emsp;提交容器为新的镜像\n```sh\ndocker commit -m \"Add vim editor\" -a \"mccxadmin\" my-ubuntu my-ubuntu-vim:1.0\n```\n&emsp;&emsp;其中-m为添加提交信息，说明修改内容，-a作者信息，my-ubuntu为源容器名称，后者为新镜像的名称和标签。\n\n&emsp;&emsp;验证新镜像\n```sh\ndocker images\n```\n\n## 容器管理\n1. 运行容器\n```sh\ndocker run -d --name my-nginx -p 8080:80 nginx\n```\n1. 查看运行中的容器\n\n&emsp;&emsp;显示所有运行中的容器\n```sh\ndocker ps\n```\n&emsp;&emsp;显示所有已停止的容器\n```sh\ndocker ps -a\n```\n3. 进入容器\n```sh\ndocker exec -it my-nginx bash\n```\n&emsp;&emsp;-it让容器交互式运行Bash命令行。\n\n4. 停止和删除容器\n```sh\ndocker stop my-nginx    # 停止容器\ndocker rm my-nginx      # 删除容器\n```\n&emsp;&emsp;docker rm -f my-nginx强制删除正在运行的容器\n\n5. 自动重启容器\n```sh\ndocker run -d --restart=always --name auto-container my-app\n```\n&emsp;&emsp;--restart-always使容器在崩溃后自动重启，适用于生产环境。\n\n## 数据持久化\n&emsp;&emsp;容器本质上式临时的，重启或删除后，内部数据会丢失，数据持久化确保数据库、日志、配置文件等关键数据不会因容器销毁而丢失，一种方式式将宿主机目录映射到容器内。基本用法如下：\n```sh\ndocker run -d -v /data/app:/app my-app\n```\n&emsp;&emsp;这里宿主机目录：容器内目录，数据会保存在宿主机上。\n\n## 网络配置\n&emsp;&emsp;Docker提供了多种网络模式，可以直接使用宿主机网络，性能能高。容器中的端口直接暴露在宿主机上，省去了-p端口映射。\n```sh\ndocker run -d --network=host nginx\n```\n# Docker进阶用法\n## Dockerfile编写与优化\n## Docker Compose简介\n## 常见服务部署\n## 通过SSH远程登录Docker容器\n&emsp;&emsp;在Docker容器中安装SSH服务器并修改SSH端口，允许SSH远程登录容器。默认情况下，Docker容器是无SSH服务器的，如果需要远程SSH进入容器，需要手动安装和配置openssh-server。\n\n1. 使用--network=host时\n\n&emsp;&emsp;当使用--network=host，容器中的SSH端口会直接映射到宿主机，无需使用-p选项进行端口映射。这种情况下配置步骤如下：\n\n&emsp;&emsp;在容器内安装OpenSSH Server\n```sh\nsed -i s@/archive.ubuntu.com/@/mirrors.tuna.tsinghua.edu.cn/@g /etc/apt/sources.list && apt-get update -y\napt install -y openssh-server\n```\n&emsp;&emsp;设置SSH监听的端口号，允许root通过SSH直接登录，SSH允许密码登录：\n```sh\nPORT=10086\nsed -i -e \"s/^#Port 22/Port $PORT/\" \\\n       -e 's/^#PermitRootLogin prohibit-password/PermitRootLogin yes/' \\\n       -e 's/^#PasswordAuthentication yes/PasswordAuthentication yes/' /etc/ssh/sshd_config\n```\n&emsp;&emsp;设置密码，启动SSH服务器\n```sh\necho 'root:root' | chpasswd && /etc/init.d/ssh start\n```\n\n2. 使用-p时\n\n&emsp;&emsp;使用-p 10086:22表示把容器的22端口映射到宿主机的10086端口，这样可以通过ssh root@宿主机IP -p 10086访问。\n\n&emsp;&emsp;在容器内安装并启动SSH服务\n```sh\napt update && apt install -y openssh-server\nmkdir /var/run/sshd\necho 'root:root' | chpasswd  # 设置 root 账户密码\nsed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config\nsed -i 's/#PasswordAuthentication no/PasswordAuthentication yes/' /etc/ssh/sshd_config\nservice ssh restart  # 启动 SSH 服务\n```\n# 相关链接\n&emsp;&emsp;docker仓库：https://github.com/docker-archive/docker-ce\n&emsp;&emsp;docker官网：https://www.docker.com/"},{"title":"面试","url":"/2024/02/15/面试/","content":"\n## 教育经历\n1. 本硕毕业与bit, 专业是什么，研究方向是什么\n\n## 工作经历\n1. 描述从研究生到现在做的方向和事情，简短概括\n\n## 专业技能\n1. 简要概括，描述出自己掌握的程度。比如：雷达检测跟踪算法，测量算法研究的较多，c++ cuda使用过\n###  目标检测和目标跟踪\n1. 看论文\n   1. CFAR检测的原理：\n   2. 卡尔曼滤波原理\n   3. EKF和UKF的原理\n   4. 数据关联算法最近邻域与概率密度数据关联算法\n   5. 车载毫米波雷达的标定\n   6. 车载毫米波雷达自车速度估计\n\n### 目标测量\n1. 测速、测距、测角原理熟悉下\n   1. 测距的原理\n   2. 测速的原理\n   3. 测角的原理\n   4. wlp超分辨测角\n   5. 解速度模糊（TDM参差帧，余数定理，chirpdelay，航迹差分）\n   6. 抗干扰的方法（FH，CS，PS）\n   7. 干扰抑制的方法\n\n### FMCW和MIMO\n\n### matlab\n\n### linux\n1. 基本命令熟悉： `ls cd pwd find grep rm mkdir touch`\n2. `git`\n\n### c++\n1. 基础语法 c++ primier\n\n   - static的作用\n\n      static修饰变量能够改变变量的生命周期和存储位置，存储在全局存储空间中生命周期是整个程序的运行周期；\n\n      static修饰函数使得该函数的作用域限定在定义该函数的文件内。\n\n      static成员函数只能调用static类型的成员变量，因为该类型的函数可由类名直接调用，没有对象在内存中就没有对象的普通成员变量，static变量生命周期是整个程序执行周期与对象无关。\n\n      static成员变量被所有的对象共用，可以用类名直接访问。\n\n   - 引用和指针的区别\n\n      引用是变量的别名，指针是一个变量，它的值是指向变量的地址； 变量是内存的一个位置，地址是这个内存位置的索引。\n\n   - 封装多态和继承（面向对象编程的3个特性）\n\n      把数据和函数功能封装在一起，多态包含重载\n\n   - 虚析构函数的作用\n\n      虚析构函数保证子类被正常析构，子类重写基类的析构函数，指向子类对象的基类类型指针会调用子类的析构函数释放子类对象，\n\n   - struct和类的区别\n\n      struct默认是public的，类默认是private\n\n   - const的作用\n      const修饰变量表示初始化后变量的值不可改变，const修饰指针表示指针不可改变；运行时不可改变。\n      \n   - inline\n\n      将调用函数的位置用函数体替代在编译的时候。运行时不需要函数调用，速度更快，但是代码可能会变得臃肿。\n\n   - #define\n\n      宏定义，用字符串替换字符串。\n\n     \n   \n      \n\n2. cmake\n\n### cuda\n1. 看下原理\n\n   1. GPU的硬件模型\n\n      GPU由几十至成百个SM组成，每个SM被分为多个sub-partition，每个sub-partition包含多个cuda core和少数tensor core，除了外挂的显存GPU内部包含L2 cache全局可见，L1 cache，shared memory，它们共用同一个物理内存区域，对一个SM可见，此外每个sub partition还包含寄存器文件等。\n\n   2. GPU的编程模型\n\n      一个kernel对应一个grid，每个grid被分成多个block，每个block包含多个thread，每个block在一个SM上被执行，被划分为多个warp，这些warp被分配给每个sub-partition来执行，每个warp有32线程。\n\n      nvcc将主机端和设备端的代码分别编译、链接生成可执行文件，主机端的代码由CPU执行，设备端的代码由cuda runtime支持在设备端执行。\n\n\n## 项目经历\n\n1. 叙述一遍，有逻辑\n\t- 项目1： 设计 -> 实现 -> 定点化 -> 工程化 -> 功能安全 -> 文档 -> 专利\n\t  - mini算法的整体处理流程\n\t  - 定点化过程与精度的分析\n\t  - 测试case的设计\n\t  - 功能安全设计方法\n\t- 项目2：重构 -> 抗干扰 -> 测试分析问题原因 -> 对比\n\t  - 原始平台的算法流程与原理\n\t  - 原始平台测试的问题与解决\n\t  - 新平台的算法流程与搭建过程\n\t  - 新平台测试的问题（主要是没有搞定移相器的校准）\n\n\n## 专利\n1. 回顾一下\n1. 问就介绍"},{"title":"matlab查看工程中函数的调用关系","url":"/2023/09/25/matlab查看工程中函数的调用关系/","content":"在 MATLAB 中，你可以使用 \"Dependency Analysis\"（依赖分析）工具来快速查看函数之间的调用关系。这个工具可以帮助你理解你的代码是如何相互连接的，特别是在大型项目中。\n## 步骤\n1. 打开 MATLAB 并打开你的项目或代码文件。\n2. 在 MATLAB 工具栏上选择 \"Editor\"（编辑器）标签。\n3. 在编辑器中，打开你想要分析的主函数或代码文件。\n4. 在编辑器中，右键单击函数名称，然后从弹出菜单中选择 \"Show Dependencies\"（显示依赖关系）。\n\n## 依赖分析工具\n依赖分析工具将在 MATLAB 窗口中显示函数的依赖关系图。这个图示表示了主函数和相关函数之间的调用关系，以及函数之间的依赖关系。\n你可以在依赖分析工具中浏览不同函数之间的连接，单击节点以查看详细信息，包括调用图、输入和输出等。\n请注意，依赖分析工具可以帮助你可视化函数之间的调用关系，但对于大型项目或复杂代码库，它可能会变得复杂。因此，在代码设计和编写时，良好的代码结构、注释和模块化可以更好地帮助你管理代码的调用关系。\n"},{"title":"电磁波概念","url":"/2023/09/25/电磁波概念/","content":"##  定义\n\n电磁波是一种由电场和磁场相互作用产生的波动现象。它是由振荡的电荷或电流在空间中传播而形成的无质量粒子——光子的传播方式。电磁波具有以下特性：\n\n1. 频率和波长：电磁波的特征由其频率和波长确定。频率表示单位时间内波动的周期数，以赫兹（Hz）为单位；波长表示连续波峰之间的距离，以米为单位。电磁波的不同频率和波长对应不同的种类，包括无线电波、微波、红外线、可见光、紫外线、X射线和γ射线。\n2. 传播速度：在真空中，电磁波的传播速度是恒定的，称为光速。光速约为每秒 3 × 10^8 米，常用符号 c 表示。光速是自然界中最快的速度，它在不同介质中会有略微变化。\n3. 双重性质：电磁波既具有波动性，也具有粒子性。根据波粒二象性理论，电磁波可以看作是由光子组成的粒子流，这些光子具有能量和动量。\n4. 干涉和衍射：电磁波表现出干涉和衍射现象。干涉是指两个或多个波相互叠加产生增强或抵消的现象，形成明暗相间的干涉图样。衍射是指波通过障碍物或穿过狭缝后发生弯曲和扩散的现象。\n5. 吸收和透射：不同物质对电磁波的吸收和透射能力不同。某些物质对特定频率的电磁波有较高的吸收能力，而其他物质则对该频率的电磁波具有较高的透射能力。\n\n电磁波的应用广泛，涵盖了许多领域，包括但不限于：\n\n1. 通信：电磁波是无线通信的基础，包括无线电、微波、卫星通信、移动通信等。\n2. 医学影像：X射线、核磁共振（MRI）、超声波等电磁波用于医学影像和诊断。\n3. 光学技术：可见光波段的电磁波被用于光学显微镜、激光技术、光纤通信、光传感器等。\n4. 天文学：通过观测和分析电磁波，天文学家能够研究和了解宇宙中的天体和现象。\n5. 辐射治疗和辐射检测：电磁波（如γ射线）被用于癌症治疗和辐射检测。\n6. 无人机和雷达技术：微波和雷达技术使用电磁波进行目标探测、跟踪和测距。\n\n以上仅是电磁波的一些特性和应用领域的简要介绍，电磁波的研究和应用在许多其他领域中也具有重要作用\n\n##  波长与频率\n\n电磁波的波长和频率之间存在一个简单的关系，由光速（速度）来连接它们。这个关系可以由以下公式表示：\n\nc = λν\n\n其中，\n\n- c 是光速，即电磁波在真空中的传播速度，约等于 3 × 10^8 米/秒。\n- λ 是电磁波的波长，表示连续波峰之间的距离，以米为单位。\n- ν 是电磁波的频率，表示单位时间内波动的周期数，以赫兹（Hz）为单位。\n\n这个公式说明了电磁波的波长和频率之间的倒数关系。具体而言，频率等于波速除以波长，或者波长等于波速除以频率。\n\n例如，对于可见光，它的波长范围大约在 400 纳米到 700 纳米之间。假设我们取其中的一个波长 λ = 500 纳米，带入公式 c = λν，可以求解频率 ν： c = λν 3 × 10^8 = (500 × 10^(-9)) × ν ν ≈ 6 × 10^14 Hz\n\n因此，对应波长为 500 纳米的可见光具有大约 6 × 10^14 赫兹的频率。\n\n这个关系表明，波长和频率是电磁波的基本属性，它们之间具有互相确定的关系。当波长增加时，频率减小；当波长减小时，频率增加。\n\n## 相位\n\n相位（Phase）= 距离 / 波长 × 2π 其中， 距离是指电磁波传播的距离，通常以长度单位（如米）表示。 波长是电磁波的波长，表示一个完整波周期的长度，也以长度单位（如米）表示。 2π 是圆周率 π 的倍数，用来将相位从弧度单位转换为角度单位（弧度=角度 × π / 180）。 这个公式描述了电磁波传播中相位的变化。根据这个公式，当传播距离是波长的整数倍时，相位的变化是完整的周期（2π的倍数）；当传播距离是波长的一半时，相位的变化是半个周期（π的倍数）。 相位的概念在电磁波的分析和处理中非常重要，它决定了波的位置、波的形状以及与其他波的干涉和合成等现象。\n\n\n\n"},{"title":"matlab中标记3D图形中的某点","url":"/2023/09/25/matlab中标记3D图形中的某点/","content":"## 目的\n在雷达算法调试的过程中，为了方便查看2D检测的结果，将检测点结果可视化在三维频谱上。\n\n## 方法\n``` matlab\n% x,y,z是要标记的点的坐标\n% r.表示颜色\n% ‘markersize’，30是点的大小\nplot3(x,y,z,'r.','markersize','30');\n```\n## 注意\n大部分情况下需要同时选取数组的多个元素，使用sub2ind函数。\n例子：对于矩阵A想要取出位置为[1,1]和位置[3,3]的元素，ind = [1,1;3,3]，即第一列为行数，第二列为列数，命令A(sub2ind(size(A),ind(:,1),ind(:,2)))可达到取出该元素的目的。即plot3中的z。"},{"title":"matlab_check_platform","url":"/2023/09/25/matlab-check-platform/","content":"\n## matlab中查看当前运行平台的方法\n``` matlab\nif ismac()\n    % Code to run on Mac platform\nelseif isunix()\n    % Code to run on Linux platform\nelseif ispc()\n    % Code to run on Windows platform\nelse\n    disp('Platform not supported')\nend\n```\n"},{"title":"dB,dBm与dBw","url":"/2023/09/25/dB-dBm与dBw/","content":"\n# dB、dBm与dBw\n\n## dB\n\n​\t\tdB是无线通信中的基本概念。如“传播损耗是 dB”、“发射功率是dBm”、“天线增益是dBi”。\n\n​\t\t最常见的3dB，它在功率图或者误码率图中经常出现，下降3dB就是指功率下降一半，3dB点指的就是半功率点。\n\n​\t\t+3dB表示增大为原来的两倍，-3dB表示下降为原来的1/2.\n\n> dB = 10lg(P1/P0)\n\n​\t\tdB表示功率P1相对于参考功率P0的大小关系。\n\n​\t\t常用的dB值中，+10dB表示功率增加为原来的10倍，-10dB表示功率减小为原来的1/10.\n\n​\t\t可见，dB是一个相对值，它的作用是把一个很大或者很小的数，用一个简短的形式表达出来。这可以极大的方便我们的计算和描述。尤其是在绘制表格的时候，如果没有换算成dB，那么坐标轴将很长无法表示。\n\n> 功率变化增大到原来的100000000倍，用dB表示为10lg10^8 = 80dB，减小到原来的0.00000001倍，用dB表示为-80dB。\n\n## dBm与dBw\n\n​\t\t这是最常用的两个单位。它们对应的就是把dB公式中的参考功率P0分别变换成1mW、1W。由于1mW、1W都是确定的值，因此dBm和dBw都可以表示功率的绝对值。\n\n![convert](/images/db/convert.png)\n\n​\t\t这里需要特别记住的是1W=30dBm。\n\n> 例子：44dBm = 30dBm + 10dB + 10dB - 3dB -3dB，\n> 因此44dBm = 1W×10×10/2/2 = 25W\n\n​\t\t这里需要注意，等式右侧除了30dBm，其余的拆分项都要用dB表示。即用一个dBx减另一个dBx时，得到的结果用dB表示。如功率46dBm比功率40dBm大6dB。\n\n​\t\t另外要注意dB是相对值，而dBm和dBw则对应的是绝对值。\n\n> 例如46dB表示P1为P0的4万倍，46dBm表示P1的值为40W。\n\n​\t\tdB家族中常见的还有dBi、dBd、dBc。 它们的计算方法与dB的计算方法完全一样，表示的还是功率的相对值。不同的是，它们的参考基准不同，即分母上的参考功率P0 所代表的含义不同。\n\n​\t\t此外，dB家族不仅可以表示功率的增益和损耗，还可以表示电压、电流、音频等，大家要具体场景具体应用。需要注意的是，对于功率的增益，我们用10lg(Po /Pi )，对于电压和电流的增益，要用20lg(Vo /Vi )、20lg(Io /Ii)。\n\n## dB家族\n![family](/images/db/family.png)\n\n"},{"title":"傅里叶变换","url":"/2023/09/25/傅里叶变换/","content":"\n\n\n## 概述\n\n`快速傅里叶变换（Fast Fourier Transform，FFT）`是一种高效计算离散傅里叶变换（Discrete Fourier Transform，DFT）的算法。它通过利用傅里叶变换的对称性和周期性，将计算复杂度从O(N^2)降低到O(N log N)，其中N是信号长度。\n\n傅里叶变换将一个信号（或序列）从时域转换到频域，它将信号分解为一系列正弦和余弦函数（频谱成分），表示每个频率成分的振幅和相位。DFT是计算离散信号的傅里叶变换，它将信号离散化为一系列离散采样点。\n\nFFT算法的核心思想是基于\"分治法\"，它将DFT的计算分解为一系列较小的DFT计算。它利用了傅里叶变换的周期性和对称性质，将一个长度为N的DFT分解为多个长度为N/2的DFT，然后再将这些子问题分解为更小的子问题，以此类推，直到最终计算得到长度为1的DFT。\n\n## FFT算法的主要步骤\n\n1. 如果输入序列长度为1，则直接返回该值作为DFT结果。\n2. 将输入序列分为偶数索引和奇数索引两个子序列。\n3. 对这两个子序列分别进行递归的FFT计算，得到它们的DFT结果。\n4. 利用DFT结果计算原始序列的DFT结果。这一步骤涉及到频域中的旋转因子（复数），用于将两个子序列的DFT结果结合起来得到原始序列的DFT结果。\n5. 重复上述步骤，直到得到最终的DFT结果。\n\nFFT算法通过将问题分解为更小的子问题，有效地减少了计算量。它的关键在于计算复杂度为O(N log N)，相比直接计算DFT的O(N^2)大大降低了计算时间。因此，FFT广泛应用于信号处理、频谱分析、图像处理和许多其他领域。\n\nFFT算法的主要思想是通过将信号分解为多个子问题，利用傅里叶变换的性质减少计算量。其中最常用的是Cooley-Tukey算法，该算法使用了迭代的方式，将FFT问题分解为较小规模的子问题。\n\n## Cooley-Tukey算法的基本原理\n\n1. 将输入信号分为偶数索引和奇数索引两个子序列。\n2. 对子序列进行递归地进行FFT计算。\n3. 计算旋转因子，通过乘以旋转因子将奇数索引子序列与偶数索引子序列合并。\n4. 重复以上步骤，直到最后得到FFT结果。\n\nCooley-Tukey算法利用了傅里叶变换的对称性和周期性，通过将问题分解为较小规模的子问题，大大减少了计算量。该算法的时间复杂度为O(NlogN)，比直接计算傅里叶变换的O(N^2)更高效。\n\nFFT算法在实际应用中具有广泛的应用，例如频谱分析、滤波、信号压缩等。它能够有效地处理大量数据，并提供了高精度和高效率的频域分析。"},{"title":"git","url":"/2022/11/13/git/","content":"\n- [Git基础概念](#git基础概念)\n  - [Git vs SVN: 为什么选择Git？](#git-vs-svn-为什么选择git)\n  - [Git版本控制的基本原理](#git版本控制的基本原理)\n  - [Git的核心概念](#git的核心概念)\n  - [Git的工作区域](#git的工作区域)\n- [Git安装与配置](#git安装与配置)\n  - [Linux下的Git安装](#linux下的git安装)\n  - [Git配置](#git配置)\n  - [配置SSH Key以连接GitHub/GitLab](#配置ssh-key以连接githubgitlab)\n- [Git基本操作](#git基本操作)\n  - [创建和初始化仓库](#创建和初始化仓库)\n  - [克隆远程仓库](#克隆远程仓库)\n  - [提交更改](#提交更改)\n  - [查看提交记录](#查看提交记录)\n  - [分支管理](#分支管理)\n- [远程仓库管理](#远程仓库管理)\n  - [添加远程仓库](#添加远程仓库)\n  - [推送代码](#推送代码)\n  - [拉取和同步代码](#拉取和同步代码)\n  - [处理冲突](#处理冲突)\n  - [Fork和Pull Request的使用](#fork和pull-request的使用)\n- [Git进阶操作](#git进阶操作)\n  - [Git Reset vs. Revert vs. Checkout](#git-reset-vs-revert-vs-checkout)\n  - [Git Rebase的应用场景](#git-rebase的应用场景)\n  - [Cherry-pick选取提交](#cherry-pick选取提交)\n  - [交互式Rebase](#交互式rebase)\n  - [Submodule](#submodule)\n- [GitHub \\& GitLab相关](#github--gitlab相关)\n  - [GitHub/GitLab的基本使用](#githubgitlab的基本使用)\n  - [Github Actions/GitLab CI/CD](#github-actionsgitlab-cicd)\n  - [Webhook和自动化部署](#webhook和自动化部署)\n  - [私有仓库和团队协作](#私有仓库和团队协作)\n- [Git高级技巧](#git高级技巧)\n  - [Git Hooks](#git-hooks)\n  - [Git LFS](#git-lfs)\n  - [Git Bisect](#git-bisect)\n  - [Git Blame](#git-blame)\n  - [Git Worktree](#git-worktree)\n- [Git常见问题与解决方案](#git常见问题与解决方案)\n  - [如何回滚误操作？](#如何回滚误操作)\n  - [如何恢复误删分支？](#如何恢复误删分支)\n  - [如何处理合并冲突？](#如何处理合并冲突)\n  - [如何解决detached HEAD问题？](#如何解决detached-head问题)\n  - [如何高效管理.gitigonre?](#如何高效管理gitigonre)\n\n\n# Git基础概念\n## Git vs SVN: 为什么选择Git？\n &emsp;&emsp;Git和SVN时常见的版本控制工具，但是Git相比于SVN具有更多优势：\n1. **分布式版本控制**：Git每个用户都有一份完整的仓库副本，而SVN仅仅是一个主仓库与涉及其的源码文件。\n2. **快速操作**：由于大量操作都在本地运行，Git上传/下载速度更快，SVN则需要每次连接远端。\n3. **强大的分支管理**：Git允许用户完全独立地创建、合并、删除分支，SVN则需要专门提交。\n4. **更好的回溯功能**：由于Git采用离散式数据库，任何时刻都可以回溯到任意版本。\n## Git版本控制的基本原理\n参考链接：[text](https://git-scm.com/book/zh/v2)\n\n&emsp;&emsp;版本控制是一种记录一个或若干文件内容变化，以便来查阅特定版本修订情况的系统。Git是一种分布式版本控制一同，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来，包括完整的历史记录。任何一处协同工作的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的克隆操作，都是一次对代码仓库的完整备份。\n![alt text](image.png)\n\n&emsp;&emsp;Git是把数据看作是对小型我呢见系统的一系列快照。在Git中，每当提交更新或保存项目状态时，它就会对当时的全部文件创建一个快照并保存这个快照的索引。为了效率，如果文件没有修改，Git不再重新存储该文件，而是只保留一个链接指向之前存储的文件，Git对待数据像是一个快照流。\n![alt text](image-1.png)\n\n&emsp;&emsp;Git中所有的数据在存储前都计算校验和，然后以校验和来引用。Git用以计算校验和的机制叫做SHA-1散列（hash,哈希）。这是一个由40个十六进制字符（0-9和a-f）组成的字符串，基于Git中文件的内容或目录结构计算出来。Git数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名，SHA-l哈希看起来是这样：\n```\n24b9da6552252987aa493b52f8696cd6d3b00373\n```\n\n## Git的核心概念\n1. **commit(提交)**：Git保存的并不是文件修改，而是文件状态。每一次commit都不会覆盖之前的提交，可以随时回溯。\n2. **Branch(分支)**:分支允许将工作分离在不同分支中，最终可以合并回主分支。\n3. **Merge(合并)**:将不同分支的作业合并在一起，可以式普通合并或rebase操作。\n4. **Rebase**:重排commit历史，可以把一个分支重新展示为另一个分支上的展开。\n5. **Tag(标签)**:对特定提交点做标记，通常用于与版本关联。\n6. **Stach**:暂存工作状态，在切换分支时保持现有工作不丢失。\n\n## Git的工作区域\n&emsp;&emsp;Git使用三个区域来管理代码的状态：\n1. **Working Directory(工作目录)**:存放正在工作的文件。是对项目的某个版本独立提取出来的内容。这些从Git仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n2. **Staging Area(待提交区)**:git add进入此区域，为提交准备。暂存区是一个文件，保存了下次要提交的文件列表信息，一般在Git仓库目录中。按照Git的术语叫做索引，不过一般说法还是叫暂存区。\n3. **Repository(本地仓库)**:git commit后保存在此，可以添加远程仓库以使其他人使用。Git仓库目录是Git用来保存项目的元数据和对象数据库的地方。这是Git中最重要的部分，从其他计算机克隆仓库时，复制的就是这里的数据。\n![alt text](image-2.png)\n\n&emsp;&emsp;Git有三种状态，你的文件可能处于其中之一：已提交（committed）、已修改（modified）和已暂存（staged）。\n1. 已修改表示修改了文件，但还没保存到数据库中。\n2. 已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n3. 已提交表示数据已经安全地保存在本地数据库中。\n\n# Git安装与配置\n## Linux下的Git安装\n&emsp;&emsp;Linux各发行版均可通过包管理器安装Git,Ubuntu下：\n```bash\nsudo apt update\nsudo apt install git -y\n```\n\n## Git配置\n&emsp;&emsp;安装完成后，需要进行一些基本配置，如用户信息、别名、编辑器等。\nGit提交时需要记录用户信息，建议配置全局用户和邮箱：\n```bash\ngit config --global user.name \"你的名字\"\ngit config --global user.email \"你的邮箱@example.com\"\n```\n&emsp;&emsp;查看当前配置\n```bash\ngit config --list\n```\n\n## 配置SSH Key以连接GitHub/GitLab\n&emsp;&emsp;为了方便推送代码到GitHub/GitLab，需要配置SSH Key。\n1. 生成SSH Key\n&emsp;&emsp;在终端输入以下命令：\n```bash\nssh-keygen -t rsa -b 4096 -C \"你的邮箱@example.com\"\n```\n\n&emsp;&emsp;然后按回车，使用默认路径~/.ssh/id_rsa，并设置密码（可留空）。\n\n2. 添加SSH Key到GitHub\n&emsp;&emsp;复制SSH公钥：\n```bash\ncat ~/.ssh/id_rsa.hub\n```\n&emsp;&emsp;登录GitHub，进入Settings->SSH and GPG keys，点击New SSH Key，粘贴公钥。\n\n3. 添加SSH Key到GitLab\n&emsp;&emsp;登录GitLab，进入Preferences->SSH Keys,粘贴公钥。\n\n4. 测试SSH连接\n&emsp;&emsp;GitHub\n```bash\nssh -T git@github.com\n```\n&emsp;&emsp;GitLab\n```bash\nssh -T git@gitlab.com\n```\n&emsp;&emsp;如果看到 Hi username! You've successfully authenticated. 说明配置成功。\n\n# Git基本操作\n## 创建和初始化仓库\n## 克隆远程仓库\n## 提交更改\n## 查看提交记录\n## 分支管理\n\n# 远程仓库管理\n## 添加远程仓库\n## 推送代码\n## 拉取和同步代码\n## 处理冲突\n## Fork和Pull Request的使用\n\n# Git进阶操作\n## Git Reset vs. Revert vs. Checkout\n## Git Rebase的应用场景\n## Cherry-pick选取提交\n## 交互式Rebase\n## Submodule\n\n# GitHub & GitLab相关\n## GitHub/GitLab的基本使用\n## Github Actions/GitLab CI/CD\n## Webhook和自动化部署\n## 私有仓库和团队协作\n\n# Git高级技巧\n## Git Hooks\n## Git LFS\n## Git Bisect\n## Git Blame\n## Git Worktree\n\n# Git常见问题与解决方案\n## 如何回滚误操作？\n## 如何恢复误删分支？\n## 如何处理合并冲突？\n## 如何解决detached HEAD问题？\n## 如何高效管理.gitigonre?"},{"title":"原码反码与补码","url":"/2022/11/13/原码反码与补码/","content":"\n二进制原码、反码与补码\n\n1. `原码`\n\n原码是指将最高位作为符号位(0表示正，1表示负)，其它数字位代表数值本身的绝对值的数字表示方式。\n\n2. `反码`\n\n反码表示规则为：如果是正数，则表示方法和原码一样；如果是负数，符号位不变，其余各位取反，则得到这个数字的反码表示形式。\n\n例如，数字6 在8位 计算机中的反码就是它的原码：00000110\n\n数字－6 在 8位计算机中的反码为：11111001\n\n3. `补码`\n\n补码是计算机表示数据的一般方式，其规则为：如果是正数，则表示方法和原码一样；如果是负数，则将数字的反码加上1(相当于将原码数值位取反然后在最低位加1)。\n\n　　例如：数字6 在8位 计算机中的补码就是它的原码：00000110\n　　            数字－6 在8 位 计算机中的补码为：1111 1010"},{"title":"Org Mode","url":"/2021/09/07/Org-Mode/","content":"\n## Links\n1. [org mode](https://orgmode.org/)\n","tags":["OrgMode"],"categories":["Emacs","OrgMode"]},{"title":"about","url":"/about/index-1.html"},{"title":"about","url":"/about/index.html","content":"\n## 个人简介\n郝智\n毕业于北京理工大学\n\n## 联系方式\n1. mail: haozhibit@163.com\n"},{"title":"categories","url":"/categories/index.html"},{"title":"tags","url":"/tags/index.html"}]